{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align=center><strong><em>Template pout le machine learning</em></strong></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Mise en place de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Importer toutes les librairies nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour le Dataframe\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# pour les graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\") \n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# pour la transformation de données manquante\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# pour la transformation de données catégorielles\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# pour splitter le jeu de données en un jeu d'entrainement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pour la mise à l'echelle\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "\n",
    "# pour le choix du tri de variables\n",
    "from sklearn.feature_selection import VarianceThreshold # permet de pas prendre en compte les variables qui varient que très peu\n",
    "from sklearn.feature_selection import SelectKBest # permet de garder les variables qui ont le plus d'influence sur la sortie\n",
    "from sklearn.feature_selection import SelectFromModel # à utiliser avec un estimateur... à approfondir !!!\n",
    "\n",
    "# pour le choix du model... ça dépend du type et des quantités de données que nous disposons...voir graphique ci-dessous\n",
    "# exemple :\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# pour la cross validation:\n",
    "    # pour le tri du jeu d'entrainement\n",
    "from sklearn.model_selection import KFold # partage le set en n groupes de manière aléatoire \n",
    "from sklearn.model_selection import LeaveOneOut # le jeu va être validé sur un seul individu => temps de calculs très long\n",
    "from sklearn.model_selection import ShuffleSplit # idem KFold sauf que le jeu va être mélanger aprés chaque validation\n",
    "from sklearn.model_selection import StratifiedKFold # permet de faire des groupes homogènes contenent chacun la même proportion de chaque variables\n",
    "from sklearn.model_selection import GroupKFold # si une variable est catégorielle => avoir autant de chaque catégorie exemple autant de 1er classe que de 2nd classe\n",
    "    # pour réaliser le tri sur le jeu d'entrainement et des variables simplement\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# pour obtenir le score d'un model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# pour la vaildation curve\n",
    "from sklearn.model_selection import validation_curve # permet de visualiser les résultats avec les différents hyperparamètres\n",
    "\n",
    "# pour la learning curve\n",
    "from sklearn.model_selection import learning_curve # permet de savoir s'il y a assez de données ou si plus de données donneraient une meilleure performance\n",
    "\n",
    "# pour la sauvegarde des meilleurs paramètres\n",
    "import pickle\n",
    "import joblib # à approfondir ... différence entre pickle et joblib\n",
    "\n",
    "# pour un obtenir le temps d'un calcul\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tableau.png\" width=\"1000\" height=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mon_fichier.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # permet d'avoir une bonne visualisation du dataset, donne les infos suivantes :\n",
    "            # Nombre de lignes\n",
    "            # Nom des variables\n",
    "            # Le type des variables (object, int ,float...)\n",
    "            # S'il y a des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna()   # Supprime toutes les lignes où il y a un NaN.\n",
    "                # Peu conseillé car ça peu supprimer énormémément de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated()] # permet de voir les lignes exactement identique\n",
    "data.drop_duplicates()  # permet de garder une seule ligne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour traiter une valeur manquante il vaut mieux utiliser SimpleImputer\n",
    "# qui permet d'affecter une valeur à un NaN suivant une stratégie :\n",
    "data[\"categorielle\"]= SimpleImputer(strategy='most_frequent', missing_values=np.nan).fit_transform(data[[\"categorielle\"]])\n",
    "data[\"continue\"] = SimpleImputer(strategy='mean', missing_values=np.nan).fit_transform(data[[\"continue\"]]) # median aurait pu être une statégie ici aussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() # permet de verifier qu'il n'y a plus de valeur NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"inutile_1\", \"inutile_2\"], axis=1) # Supprime des variables inutiles exemple le numéro du ticket dans le dataset du Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # pour verifier que tout est en ordre avant l'EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- L'analyse exploratoire de données (EDA) permet de tirer des conclusions sur le rapport entre les variables et la sortie.\n",
    "- Elle nous permet aussi d'apprécier la pertinance des résultats suivant la distribution des données (un dataset avec 95% d'hommes ne nous permettra pas d'avoir de conclusions pertinantes sur le rôle du sexe)\n",
    "- On peut également voir la correlation entre deux variables. S'il y a une correlation proche de 1 entre deux variables cela nous permet d'en supprimer une afin de gagner du temps lors de la construction de notre modèle de machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Visualisation numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() # permet d'avoir une vue d'ensemble de chaque variable si elles sont numérique :\n",
    "                # minimum , maximum, moyenne, écart type...\n",
    "\n",
    "data[\"categorielle\"].value_counts() # permet de voir les différentes catégories ainsi que leur répartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Visualisation graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib permet plus de détails et de complexités\n",
    "# Seaborn utilise matplotlib mais il permet de faire un graphique complexe en une seule ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec matplotlib\n",
    "\n",
    "plt.figure(figsize=(20,5)) # ouverture d'un nouveau graphique, figsize permet de lui donner une taille. voir doc pour d'autres attributs\n",
    "plt.scatter(x1, y1, c = 'red') # Crée une graphique avec des points de couleur rouge. voir doc pour autre type de graphique(box,hist...)\n",
    "plt.scatter(x1,y2, c = 'blue') # il est possible de tracer plusieur courbe sur le même graphique\n",
    "plt.ylabel('label')\n",
    "plt.title('Titre_du_graphique')\n",
    "plt.legend(\"Pour la légende\")\n",
    "plt.show() # affichage du grapgique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec Seaborn et plusieurs graphique sur un seul affichage :\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(20,15)) # 4 graphique (2 lignes, 2 colonnes) taille totale 20,15 en inch\n",
    "\n",
    "sns.scatterplot(data=data,x=\"petal.length\",y=\"petal.width\",hue=\"variety\",ax=ax[0,0])    # Lechoix du type de graphique dépend du type de variable\n",
    "ax[0,0].set_title(\"Rapport entre largeur et longeur d'une petale\")                      # voir doc car beaucoup de possibilités\n",
    "                                                                                        # boxplot, violinplot, histplot, countplot....\n",
    "sns.scatterplot(data=data,x=\"petal.length\",y=\"sepal.length\",hue=\"variety\",ax=ax[0,1])\n",
    "ax[0,1].set_title(\"Rapport entre largeur d'une pétale et d'un sépal\")\n",
    "\n",
    "sns.scatterplot(data=data,x=\"petal.width\",y=\"sepal.length\",hue=\"variety\",ax=ax[1,0])\n",
    "ax[1,0].set_title(\"Rapport entre la largeur d'une pétale et la longueur d'un sépal \")\n",
    "\n",
    "sns.scatterplot(data=data,x=\"petal.length\",y=\"sepal.width\",hue=\"variety\",ax=ax[1,1])\n",
    "ax[1,1].set_title(\"Rapport entre la longeur d'une pétale et la largeur d'un sépal\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation entre les variables. Tableau de correlations avec les valeurs\n",
    "sns.heatmap(data.iloc[:,:-1].corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour voir les correlations entre des variables (continues de préférence) et une sortie catégorielle\n",
    "sns.pairplot(data=data.iloc[:,:-1],hue=\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Bilan de l'EDA : \n",
    "<ul>\n",
    "<li>Informer sur l'importance ou non d'une variable sur la sortie</li>\n",
    "<li>Informer sur la distribution des données</li>\n",
    "<li>Donner les pistes pour notre modèle de machine learning</li>\n",
    "</ul></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Transformation de varible catégorielle en variable numérique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour une seule variable:\n",
    "data[\"variable_transformée\"] = LabelEncoder().fit_transform(data[\"variable_a_tranformer\"]) # crée une nouvelle colonne à notre Dataframe\n",
    "\n",
    "# Pour plusieures variables :\n",
    "data = LabelEncoder().fit_transform(data.select_dtypes(include=['object'])) # remplace tout sans créer de nouvelles colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Splitter le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\"variables\", \"output\", test_size=0.2, random_state=2)\n",
    "\n",
    "# Le dataset sera splitté en 4 un jeu d'entrainement et jeu de test chacun \n",
    "# splitté avec d'un côté les variables et de l'autre la sortie\n",
    "# test_size permet de definir la taille du jeu de test en pourcent\n",
    "# Random permet d'avoir toujours le même tirage aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Recherche du modèle à utiliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tableau.png\" width=\"1000\" height=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Mise à l'echelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Choix du scaler avec une méthode graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2731862569.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    <center><img src=\"tableau.png\" width=\"1000\" height=\"700\"></center>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "scaler_liste= [StandardScaler(),MinMaxScaler(),RobustScaler()]\n",
    "for i in scaler_liste:\n",
    "    scaler = i.fit_transform(X_train)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    sns.kdeplot(scaler, legend=False)\n",
    "    plt.title(f\"Distribution du jeu d'entrainement avec la transformation {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Avec le score sans hyperparamètre du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_liste,score = [StandardScaler(),MinMaxScaler(),RobustScaler()],0\n",
    "for i in scaler_liste:\n",
    "    scaler = i.fit_transform(X_train)\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(scaler,y_train)\n",
    "    result = model.score(scaler,y_train)\n",
    "    print(f\"Avec le scaler \", str(i), \"le score est de \", result)\n",
    "    if result>score:\n",
    "        best_scaler=i\n",
    "        score=result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Avec choix manuel de la distribution du jeu d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 20),                  # Dictionnaire avec les hyperparamètres à tester\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "cv=KFold(5, random_state=42, shuffle=True)                      # Choix manuel de la distribution du jeu d'entrainement\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv)  # \n",
    "grid.fit(X_train, y_train)                                      # Va entrainer notre model avec toutes les combinaisons d'hyperparamètres possible\n",
    "\n",
    "print(\"Le meilleur est de \",grid.best_score_,\"avec les parametres\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Pour tester les différentes distributions et les différents hyperparamètres avec les performances et le temps de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 20),\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "model_selection ={\"StatifiedKFold\": StratifiedKFold(4),\n",
    "                \"Kfold\": KFold(5, random_state=42, shuffle=True),\n",
    "                \"LeaveOneOut\": LeaveOneOut(),                           # NE SURTOUT PAS FAIRE SUR UN GROS JEU DE DONNEES TEMPS EXTREMEMENT LONG\n",
    "                \"ShuffleSplit\": ShuffleSplit(4, test_size=0.2)}\n",
    "                \n",
    "for v in model_selection.values():\n",
    "    debut = time()\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=v)\n",
    "    grid.fit(X_train, y_train)\n",
    "    fin = time()\n",
    "\n",
    "\n",
    "    print(\"Le meilleur score avec \",str(v).split(\"(\",1)[0],\"est\",grid.best_score_,\"avec les parametres\",\n",
    "        grid.best_params_,\"calcumlé en\",round(fin-debut,2),\"secondes.\")\n",
    "\n",
    "\n",
    "# Il faudra refaire la cross validation avec le model selection qui nous interesse pour sauvegarder les best_params_ et le best_model_selection\n",
    "best_model_selection=KFold(5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "#       \n",
    "#--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(model, X_train, y_train,train_sizes=np.linspace(0.05, 1.0, 15), cv=best_model_selection)\n",
    "\n",
    "print(N)\n",
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Permet de savoir s'il faut plus de données pour que notre modèle soit plus preformant ou si nous disposons d'assez de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) Score sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = cross_val_score(KNeighborsClassifier(grid.best_params_), best_scaler.transform(X_test), y_test, cv=best_model_selection).mean()\n",
    "print(\"Sur le jeu de test on obtient un score de \",score_test*100,\"% de bonnes prédictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) Sauvegarde des meilleurs paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complet={ \"scaler\": best_scaler,\n",
    "                \"model\":,\n",
    "                \"best_param\":best_params_,\n",
    "                \"cross_val\":best_model_selection}\n",
    "joblib.dump(model_complet, 'model_iris.joblib') # à approfondir entre pickle et joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13) Mise en production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f394ba83058c5a142df3c7e87c8296842715c2e07fd446e3acfd6cb9b123e2dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
